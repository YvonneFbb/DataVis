#!/usr/bin/env python3
"""
æ··åˆå¤„ç†æµç¨‹ä¸»è„šæœ¬
Pipeline: Preprocess â†’ OCR Region Detection â†’ Character Segmentation
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Tuple
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from preprocess.core import preprocess_image
from ocr.remote_paddleocr import RemotePaddleOCRClient
from utils.path import ensure_dir

def create_pipeline_structure(base_name: str) -> Dict[str, Path]:
    """åˆ›å»ºæµæ°´çº¿ç›®å½•ç»“æ„"""
    base_path = Path("data/results")
    
    structure = {
        'preprocessed': base_path / "preprocessed" / base_name,
        'ocr': base_path / "ocr" / base_name,
        'segments': base_path / "segments" / base_name,
        'ocr_regions': base_path / "ocr" / base_name / "region_images",
        'segments_summary': base_path / "segments" / base_name / "all_characters"
    }
    
    # åˆ›å»ºæ‰€æœ‰ç›®å½•
    for path in structure.values():
        ensure_dir(str(path))
    
    return structure

def step1_preprocess(input_path: Path, output_dir: Path) -> Dict[str, Any]:
    """æ­¥éª¤1: å›¾åƒé¢„å¤„ç†"""
    print(f"\n{'='*50}")
    print(f"æ­¥éª¤1: å›¾åƒé¢„å¤„ç†")
    print(f"{'='*50}")
    
    start_time = time.time()
    
    try:
        # ä¿å­˜é¢„å¤„ç†ç»“æœè·¯å¾„
        enhanced_path = output_dir / "enhanced.jpg"
        
        # æ‰§è¡Œé¢„å¤„ç†
        success = preprocess_image(str(input_path), str(enhanced_path))
        
        if not success:
            return {'success': False, 'error': 'é¢„å¤„ç†å¤±è´¥'}
        
        # è¯»å–å¤„ç†åçš„å›¾åƒè·å–å°ºå¯¸ä¿¡æ¯
        import cv2
        enhanced_image = cv2.imread(str(enhanced_path))
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'step': 'preprocess',
            'input_image': str(input_path),
            'output_image': str(enhanced_path),
            'process_time': time.time() - start_time,
            'image_shape': enhanced_image.shape,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        with open(output_dir / "metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… é¢„å¤„ç†å®Œæˆ: {enhanced_path}")
        print(f"   å›¾åƒå°ºå¯¸: {enhanced_image.shape}")
        print(f"   å¤„ç†è€—æ—¶: {metadata['process_time']:.2f}ç§’")
        
        return {
            'success': True,
            'enhanced_path': enhanced_path,
            'metadata': metadata
        }
        
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†å¤±è´¥: {e}")
        return {'success': False, 'error': str(e)}

def step2_ocr_regions(input_path: Path, output_dir: Path, regions_dir: Path) -> Dict[str, Any]:
    """æ­¥éª¤2: OCRåŒºåŸŸæ£€æµ‹"""
    print(f"\n{'='*50}")
    print(f"æ­¥éª¤2: OCRåŒºåŸŸæ£€æµ‹")
    print(f"{'='*50}")
    
    start_time = time.time()
    
    try:
        # åˆå§‹åŒ–PaddleOCRå®¢æˆ·ç«¯
        client = RemotePaddleOCRClient()
        
        # æ‰§è¡ŒOCRè¯†åˆ«
        result = client.predict_full_document(input_path)
        
        if not result['success']:
            return {'success': False, 'error': result.get('message', 'æœªçŸ¥é”™è¯¯')}
        
        # è¯»å–åŸå›¾ç”¨äºåŒºåŸŸåˆ‡å‰²
        import cv2
        original_image = cv2.imread(str(input_path))
        
        # ä¿å­˜æ¯ä¸ªåŒºåŸŸä¸ºç‹¬ç«‹å›¾ç‰‡
        region_info_list = []
        text_regions = result['text_regions']
        
        for i, region in enumerate(text_regions):
            region_id = f"region_{i+1:03d}"
            bbox = region['bbox']
            
            # æå–åŒºåŸŸå›¾åƒ
            if isinstance(bbox[0], (list, tuple)):
                # å››ç‚¹åæ ‡æ ¼å¼ï¼Œè®¡ç®—è¾¹ç•ŒçŸ©å½¢
                points = [[int(pt[0]), int(pt[1])] for pt in bbox]
                x_coords = [pt[0] for pt in points]
                y_coords = [pt[1] for pt in points]
                x1, y1 = min(x_coords), min(y_coords)
                x2, y2 = max(x_coords), max(y_coords)
            else:
                # çŸ©å½¢æ ¼å¼
                x1, y1, x2, y2 = bbox[:4]
            
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            h, w = original_image.shape[:2]
            x1 = max(0, min(int(x1), w-1))
            y1 = max(0, min(int(y1), h-1))
            x2 = max(x1+1, min(int(x2), w))
            y2 = max(y1+1, min(int(y2), h))
            
            # æå–åŒºåŸŸå›¾åƒ
            region_image = original_image[y1:y2, x1:x2]
            
            # ä¿å­˜åŒºåŸŸå›¾åƒ
            region_path = regions_dir / f"{region_id}.jpg"
            cv2.imwrite(str(region_path), region_image)
            
            # è®°å½•åŒºåŸŸä¿¡æ¯
            region_info = {
                'id': region_id,
                'bbox': bbox,
                'rect_bbox': [x1, y1, x2, y2],  # æ ‡å‡†çŸ©å½¢åæ ‡
                'confidence': region['confidence'],
                'text': region['text'],
                'image_path': f"region_images/{region_id}.jpg",
                'image_size': [x2-x1, y2-y1]
            }
            region_info_list.append(region_info)
            
            print(f"   åŒºåŸŸ {i+1:2d}: {region['text'][:20]}... (ç½®ä¿¡åº¦: {region['confidence']:.3f})")
        
        # ä¿å­˜åŒºåŸŸä¿¡æ¯JSON
        regions_data = {
            'total_regions': len(text_regions),
            'regions': region_info_list,
            'ocr_metadata': {
                'server_time': result.get('server_time', 0),
                'total_characters': sum(len(r['text']) for r in text_regions),
                'avg_confidence': sum(r['confidence'] for r in text_regions) / len(text_regions)
            }
        }
        
        with open(output_dir / "regions.json", 'w', encoding='utf-8') as f:
            json.dump(regions_data, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºæ ‡æ³¨å›¾åƒ
        annotated_image = original_image.copy()
        from PIL import Image, ImageDraw, ImageFont
        
        pil_image = Image.fromarray(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        colors = [(255,0,0), (0,255,0), (0,0,255), (255,255,0), (255,0,255), (0,255,255)]
        
        for i, region_info in enumerate(region_info_list):
            color = colors[i % len(colors)]
            bbox = region_info['rect_bbox']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            draw.rectangle(bbox, outline=color, width=3)
            
            # ç»˜åˆ¶åŒºåŸŸID
            draw.text((bbox[0], bbox[1]-25), f"R{i+1}", fill=color)
        
        # ä¿å­˜æ ‡æ³¨å›¾åƒ
        annotated_path = output_dir / "annotated.jpg"
        annotated_cv = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        cv2.imwrite(str(annotated_path), annotated_cv)
        
        total_time = time.time() - start_time
        
        print(f"âœ… OCRåŒºåŸŸæ£€æµ‹å®Œæˆ")
        print(f"   æ£€æµ‹åˆ°åŒºåŸŸ: {len(text_regions)}ä¸ª")
        print(f"   å¹³å‡ç½®ä¿¡åº¦: {regions_data['ocr_metadata']['avg_confidence']:.3f}")
        print(f"   æ€»å­—ç¬¦æ•°: {regions_data['ocr_metadata']['total_characters']}")
        print(f"   å¤„ç†è€—æ—¶: {total_time:.2f}ç§’")
        
        return {
            'success': True,
            'regions_data': regions_data,
            'regions_dir': regions_dir,
            'process_time': total_time
        }
        
    except Exception as e:
        print(f"âŒ OCRåŒºåŸŸæ£€æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}

def step3_character_segmentation(regions_data: Dict[str, Any], regions_dir: Path, 
                                output_dir: Path, summary_dir: Path) -> Dict[str, Any]:
    """æ­¥éª¤3: å­—ç¬¦åˆ†å‰²ï¼ˆåŸºäºOCRåŒºåŸŸï¼‰"""
    print(f"\n{'='*50}")
    print(f"æ­¥éª¤3: å­—ç¬¦åˆ†å‰²")
    print(f"{'='*50}")
    
    start_time = time.time()
    
    try:
        from segmentation.vertical_hybrid_segmentation import segment_vertical_column_hybrid
        from segmentation.morphology_segmentation import segment_vertical_column_morphology
        
        total_characters = 0
        all_character_info = []
        region_results = []
        
        # å¤„ç†æ¯ä¸ªåŒºåŸŸ
        for region_info in regions_data['regions']:
            region_id = region_info['id']
            region_path = regions_dir / f"{region_id}.jpg"
            region_output_dir = output_dir / region_id
            ensure_dir(str(region_output_dir))
            
            print(f"\nå¤„ç†åŒºåŸŸ {region_id}: {region_info['text'][:30]}...")
            
            # ä¼˜å…ˆä½¿ç”¨Hybridåˆ‡å‰²ï¼›å¤±è´¥åˆ™å›é€€åˆ°å½¢æ€å­¦
            segment_result = segment_vertical_column_hybrid(
                str(region_path),
                str(region_output_dir),
                region_info,
                debug=True
            )
            if not (segment_result and segment_result.get('success') and segment_result.get('character_count', 0) > 0):
                print("   Hybridåˆ‡å‰²ç»“æœä¸ç†æƒ³ï¼Œå›é€€åˆ°å½¢æ€å­¦æ–¹æ³•â€¦")
                segment_result = segment_vertical_column_morphology(
                    str(region_path),
                    str(region_output_dir),
                    region_info
                )
            
            # segment_vertical_column è¿”å› dict æ ¼å¼
            if segment_result and segment_result.get('success'):
                char_count = segment_result['character_count']
                total_characters += char_count
                
                # ä»åˆ†å‰²ç»“æœä¸­è·å–å­—ç¬¦ä¿¡æ¯
                region_chars = []
                for i, char_data in enumerate(segment_result['characters']):
                    char_info = {
                        'char_id': f"{region_id}_char_{i+1:03d}",
                        'local_file': char_data['filename'],
                        'region_id': region_id,
                        'height': char_data['height'],
                        'width': char_data.get('width', 0),
                        'original_bbox': char_data.get('original_bbox', (0, 0, 0, 0)),
                        'refined_bbox': char_data.get('refined_bbox', (0, 0, 0, 0))
                    }
                    region_chars.append(char_info)
                
                all_character_info.extend(region_chars)
                region_results.append({
                    'region_id': region_id,
                    'character_count': char_count,
                    'characters': region_chars,
                    'ocr_text': region_info['text'],
                    'confidence': region_info['confidence'],
                    'method': segment_result.get('method', 'morphology_only'),
                    'refinement_stats': segment_result.get('refinement_stats', {})
                })
                
                method_info = segment_result.get('method', 'unknown')
                refinement_info = ""
                if 'refinement_stats' in segment_result:
                    stats = segment_result['refinement_stats']
                    boundary_adj = stats.get('boundary_adjustments', 0)
                    size_red = stats.get('size_reductions', 0)
                    refinement_info = f", è¾¹ç•Œè°ƒæ•´: {boundary_adj}ä¸ª, å°ºå¯¸ä¼˜åŒ–: {size_red}ä¸ª"
                
                print(f"   âœ… åˆ†å‰²å®Œæˆ: {char_count}ä¸ªå­—ç¬¦ (æ–¹æ³•: {method_info}{refinement_info})")
            else:
                error_msg = segment_result.get('error', 'åˆ†å‰²å¤±è´¥') if segment_result else 'åˆ†å‰²å‡½æ•°è¿”å›ç©ºç»“æœ'
                print(f"   âŒ åˆ†å‰²å¤±è´¥: {error_msg}")
                region_results.append({
                    'region_id': region_id,
                    'character_count': 0,
                    'error': error_msg
                })
        
        # åˆ›å»ºå…¨å±€å­—ç¬¦å›¾åƒæ±‡æ€»
        create_global_character_summary(all_character_info, summary_dir, regions_dir)
        
        # ä¿å­˜æ±‡æ€»ç»Ÿè®¡
        summary_data = {
            'pipeline_info': {
                'step': 'character_segmentation',
                'total_regions_processed': len([r for r in region_results if 'error' not in r]),
                'total_characters': total_characters,
                'process_time': time.time() - start_time,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'region_results': region_results,
            'character_summary': {
                'total_count': len(all_character_info),
                'avg_per_region': len(all_character_info) / len([r for r in region_results if 'error' not in r]) if any('error' not in r for r in region_results) else 0
            }
        }
        
        with open(output_dir / "summary.json", 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… å­—ç¬¦åˆ†å‰²å®Œæˆ")
        print(f"   å¤„ç†åŒºåŸŸ: {summary_data['pipeline_info']['total_regions_processed']}ä¸ª")
        print(f"   æ€»å­—ç¬¦æ•°: {total_characters}")
        print(f"   å¤„ç†è€—æ—¶: {summary_data['pipeline_info']['process_time']:.2f}ç§’")
        
        return {
            'success': True,
            'summary_data': summary_data,
            'total_characters': total_characters
        }
        
    except Exception as e:
        print(f"âŒ å­—ç¬¦åˆ†å‰²å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}

def convert_to_global_coordinates(local_chars: List[Dict], region_bbox: List[int]) -> List[Dict]:
    """å°†å±€éƒ¨åæ ‡è½¬æ¢ä¸ºå…¨å±€åæ ‡"""
    x_offset, y_offset = region_bbox[0], region_bbox[1]
    
    global_chars = []
    for char in local_chars:
        global_char = char.copy()
        # è½¬æ¢è¾¹ç•Œæ¡†åæ ‡
        if 'bbox' in char:
            local_bbox = char['bbox']
            global_bbox = [
                local_bbox[0] + x_offset,
                local_bbox[1] + y_offset,
                local_bbox[2] + x_offset,
                local_bbox[3] + y_offset
            ]
            global_char['bbox'] = global_bbox
        
        global_chars.append(global_char)
    
    return global_chars

def create_global_character_summary(all_chars: List[Dict], summary_dir: Path, regions_dir: Path) -> None:
    """åˆ›å»ºå…¨å±€å­—ç¬¦æ±‡æ€»"""
    import shutil
    
    # å°†æ‰€æœ‰å­—ç¬¦å›¾åƒå¤åˆ¶åˆ°æ±‡æ€»ç›®å½•å¹¶é‡æ–°ç¼–å·
    for i, char_info in enumerate(all_chars):
        region_id = char_info['region_id']
        local_file = char_info['local_file']
        
        # æºæ–‡ä»¶è·¯å¾„
        source_path = regions_dir.parent / "segments" / regions_dir.name / region_id / local_file
        
        # ç›®æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆå…¨å±€ç¼–å·ï¼‰
        global_filename = f"char_{i+1:04d}.jpg"
        target_path = summary_dir / global_filename
        
        if source_path.exists():
            shutil.copy2(source_path, target_path)
            char_info['global_file'] = global_filename

def run_hybrid_pipeline(input_image: str = "data/raw/demo.jpg", 
                        skip_preprocess: bool = False,
                        skip_ocr: bool = False,
                        skip_segment: bool = False) -> Dict[str, Any]:
    """è¿è¡Œå®Œæ•´çš„æ··åˆå¤„ç†æµç¨‹"""
    print(f"\nğŸš€ å¼€å§‹æ··åˆå¤„ç†æµç¨‹")
    print(f"è¾“å…¥å›¾åƒ: {input_image}")
    print(f"è·³è¿‡æ­¥éª¤: {'é¢„å¤„ç†' if skip_preprocess else ''}{'OCR' if skip_ocr else ''}{'åˆ†å‰²' if skip_segment else ''}")
    
    input_path = Path(input_image)
    if not input_path.exists():
        return {'success': False, 'error': f'è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_image}'}
    
    # åˆ›å»ºç›®å½•ç»“æ„
    base_name = input_path.stem
    dirs = create_pipeline_structure(base_name)
    
    pipeline_start = time.time()
    results = {}
    
    # æ­¥éª¤1: é¢„å¤„ç†
    if not skip_preprocess:
        step1_result = step1_preprocess(input_path, dirs['preprocessed'])
        results['step1'] = step1_result
        
        if not step1_result['success']:
            return {'success': False, 'failed_at': 'step1', 'results': results}
        enhanced_path = step1_result['enhanced_path']
    else:
        print(f"\nâ­ï¸ è·³è¿‡æ­¥éª¤1: é¢„å¤„ç†")
        # æŸ¥æ‰¾ç°æœ‰çš„é¢„å¤„ç†ç»“æœ
        enhanced_path = dirs['preprocessed'] / "enhanced.jpg"
        if not enhanced_path.exists():
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°é¢„å¤„ç†ç»“æœ {enhanced_path}ï¼Œä½¿ç”¨åŸå§‹å›¾åƒ")
            enhanced_path = input_path
        results['step1'] = {'success': True, 'skipped': True}
    
    # æ­¥éª¤2: OCRåŒºåŸŸæ£€æµ‹
    if not skip_ocr:
        step2_result = step2_ocr_regions(enhanced_path, dirs['ocr'], dirs['ocr_regions'])
        results['step2'] = step2_result
        
        if not step2_result['success']:
            return {'success': False, 'failed_at': 'step2', 'results': results}
    else:
        print(f"\nâ­ï¸ è·³è¿‡æ­¥éª¤2: OCRåŒºåŸŸæ£€æµ‹")
        # åŠ è½½ç°æœ‰çš„OCRç»“æœ
        regions_json_path = dirs['ocr'] / "regions.json"
        if not regions_json_path.exists():
            return {'success': False, 'failed_at': 'step2', 'error': f'æœªæ‰¾åˆ°OCRç»“æœæ–‡ä»¶: {regions_json_path}'}
        
        with open(regions_json_path, 'r', encoding='utf-8') as f:
            regions_data = json.load(f)
        
        step2_result = {
            'success': True,
            'regions_data': regions_data,
            'regions_dir': dirs['ocr_regions'],
            'skipped': True
        }
        results['step2'] = step2_result
    
    # æ­¥éª¤3: å­—ç¬¦åˆ†å‰²
    if not skip_segment:
        step3_result = step3_character_segmentation(
            step2_result['regions_data'],
            dirs['ocr_regions'],
            dirs['segments'],
            dirs['segments_summary']
        )
        results['step3'] = step3_result
        
        if not step3_result['success']:
            return {'success': False, 'failed_at': 'step3', 'results': results}
    else:
        print(f"\nâ­ï¸ è·³è¿‡æ­¥éª¤3: å­—ç¬¦åˆ†å‰²")
        results['step3'] = {'success': True, 'skipped': True, 'total_characters': 0}
    
    # æ±‡æ€»ç»“æœ
    total_time = time.time() - pipeline_start
    
    final_result = {
        'success': True,
        'pipeline_time': total_time,
        'results': results,
        'summary': {
            'total_regions': step2_result['regions_data']['total_regions'],
            'total_characters': step3_result['total_characters'],
            'avg_chars_per_region': step3_result['total_characters'] / step2_result['regions_data']['total_regions']
        }
    }
    
    # ä¿å­˜æµç¨‹æ±‡æ€» - ç¡®ä¿Pathå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    def convert_paths_to_str(obj):
        if isinstance(obj, Path):
            return str(obj)
        elif isinstance(obj, dict):
            return {k: convert_paths_to_str(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_paths_to_str(v) for v in obj]
        return obj
    
    serializable_result = convert_paths_to_str(final_result)
    with open(dirs['segments'] / "pipeline_summary.json", 'w', encoding='utf-8') as f:
        json.dump(serializable_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ‰ æ··åˆå¤„ç†æµç¨‹å®Œæˆï¼")
    print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"æ£€æµ‹åŒºåŸŸ: {final_result['summary']['total_regions']}ä¸ª")
    print(f"åˆ†å‰²å­—ç¬¦: {final_result['summary']['total_characters']}ä¸ª")
    print(f"å¹³å‡æ¯åŒºåŸŸ: {final_result['summary']['avg_chars_per_region']:.1f}ä¸ªå­—ç¬¦")
    
    return final_result

if __name__ == "__main__":
    import argparse
    import numpy as np
    
    parser = argparse.ArgumentParser(description='æ··åˆå¤„ç†æµç¨‹')
    parser.add_argument('--input', '-i', default='data/raw/demo.jpg', help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--skip-preprocess', action='store_true', help='è·³è¿‡é¢„å¤„ç†æ­¥éª¤')
    parser.add_argument('--skip-ocr', action='store_true', help='è·³è¿‡OCRæ­¥éª¤')
    parser.add_argument('--skip-segment', action='store_true', help='è·³è¿‡åˆ†å‰²æ­¥éª¤')
    
    args = parser.parse_args()
    
    result = run_hybrid_pipeline(
        input_image=args.input,
        skip_preprocess=args.skip_preprocess,
        skip_ocr=args.skip_ocr,
        skip_segment=args.skip_segment
    )
    
    if result['success']:
        print(f"\nâœ… æµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
    else:
        print(f"\nâŒ æµç¨‹æ‰§è¡Œå¤±è´¥äº: {result.get('failed_at', 'æœªçŸ¥é˜¶æ®µ')}")