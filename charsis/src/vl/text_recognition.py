"""
VLæ¨¡å‹æ–‡å­—è¯†åˆ«æ¨¡å— - ä¸“æ³¨äºå¤ç±æ–‡å­—è¯†åˆ«ï¼Œä¸åŒ…å«ä½ç½®æ£€æµ‹
"""
import os
import sys
import json
from typing import Dict, Any, List

# æ·»åŠ çˆ¶ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import VL_CONFIG, VL_DIR
from src.utils.path import ensure_dir
from vl.providers import SiliconFlowVision


class VLTextRecognizer:
    """
    VLæ¨¡å‹æ–‡å­—è¯†åˆ«å™¨
    ä¸“æ³¨äºå¤ç±æ–‡å­—è¯†åˆ«ï¼Œä½¿ç”¨æµå¼å“åº”
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–VLæ–‡å­—è¯†åˆ«å™¨
        """
        self.config = config or VL_CONFIG.copy()
        
        # ä»ç¯å¢ƒå˜é‡è·å–API key
        api_key = os.environ.get('SILICONFLOW_API_KEY', '')
        if api_key:
            self.config['api_key'] = api_key
        
        # è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
        self.config['timeout'] = 120  # 2åˆ†é’Ÿè¶…æ—¶
        
        self.client = SiliconFlowVision(self.config)
        
        # ç®€æ´çš„è¯†åˆ«æç¤ºè¯
        self.recognition_prompt = """è¯·è¯†åˆ«è¿™å¼ å¤ç±å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ±‰å­—ã€‚

è¦æ±‚ï¼š
1. æŒ‰ç…§ä»å³åˆ°å·¦ã€ä»ä¸Šåˆ°ä¸‹çš„é˜…è¯»é¡ºåº
2. åªè¾“å‡ºè¯†åˆ«åˆ°çš„æ±‰å­—ï¼Œç”¨ç©ºæ ¼åˆ†éš”
3. å¦‚æœæœ‰æ˜æ˜¾çš„åˆ—åˆ†éš”ï¼Œç”¨ | åˆ†éš”ä¸åŒåˆ—
4. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡æ³¨

ç¤ºä¾‹è¾“å‡ºï¼š
è­˜ è²§ è³¤ è€… ä¸ è¶³ èˆ‡ è¨€ | ä» ç¾© ç¦® æ™º ä¿¡"""
        
        print(f"VLæ–‡å­—è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æ¨¡å‹: {self.config['model']}")
    
    def recognize_text(self, image_path: str) -> Dict[str, Any]:
        """
        è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—
        
        :param image_path: å›¾ç‰‡è·¯å¾„
        :return: è¯†åˆ«ç»“æœ
        """
        if not os.path.exists(image_path):
            return {'error': f'å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}'}
        
        print(f"\n=== å¼€å§‹æ–‡å­—è¯†åˆ« ===")
        print(f"å›¾ç‰‡: {os.path.basename(image_path)}")
        
        try:
            # ä½¿ç”¨æµå¼è¯†åˆ«
            content, metadata = self.client.recognize_text_stream(
                image_path, 
                self.recognition_prompt, 
                self.config['timeout']
            )
            
            if 'error' in metadata:
                return {'error': metadata['error']}
            
            # åˆ†æè¯†åˆ«ç»“æœ
            analysis = self._analyze_text(content)
            
            result = {
                'success': True,
                'image_path': image_path,
                'recognized_text': content.strip(),
                'analysis': analysis,
                'metadata': metadata
            }
            
            print(f"âœ… è¯†åˆ«æˆåŠŸï¼Œå…±è¯†åˆ« {analysis['character_count']} ä¸ªæ±‰å­—")
            print(f"å“åº”æ—¶é—´: {metadata.get('response_time', 0):.1f}ç§’")
            
            return result
            
        except Exception as e:
            error_msg = f"æ–‡å­—è¯†åˆ«å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            return {'error': error_msg}
    
    def _analyze_text(self, content: str) -> Dict[str, Any]:
        """
        åˆ†æè¯†åˆ«ç»“æœ
        """
        import re
        
        # æå–æ±‰å­—
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', content)
        
        # åˆ†æåˆ—ç»“æ„
        columns = content.split('|') if '|' in content else [content]
        column_count = len(columns)
        
        analysis = {
            'content_length': len(content),
            'character_count': len(chinese_chars),
            'unique_characters': len(set(chinese_chars)),
            'column_count': column_count,
            'first_20_chars': ''.join(chinese_chars[:20]),
            'has_column_separators': '|' in content
        }
        
        return analysis
    
    def save_result(self, result: Dict[str, Any], output_path: str = None) -> str:
        """
        ä¿å­˜è¯†åˆ«ç»“æœ
        """
        if output_path is None:
            ensure_dir(VL_DIR)
            image_name = os.path.splitext(os.path.basename(result['image_path']))[0]
            output_path = os.path.join(VL_DIR, f"{image_name}_recognition_result.json")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ è¯†åˆ«ç»“æœå·²ä¿å­˜: {output_path}")
        return output_path


def recognize_image(image_path: str, output_path: str = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¯†åˆ«å•å¼ å›¾ç‰‡çš„æ–‡å­—
    
    :param image_path: å›¾ç‰‡è·¯å¾„
    :param output_path: ç»“æœä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    :return: è¯†åˆ«ç»“æœ
    """
    recognizer = VLTextRecognizer()
    result = recognizer.recognize_text(image_path)
    
    if result.get('success'):
        recognizer.save_result(result, output_path)
    
    return result


if __name__ == '__main__':
    # ç¤ºä¾‹ç”¨æ³•
    from config import PREPROCESSED_DIR
    
    test_image = os.path.join(PREPROCESSED_DIR, "demo_preprocessed_alpha1.5_beta10.jpg")
    
    if os.path.exists(test_image):
        print("=== VLæ–‡å­—è¯†åˆ«æµ‹è¯• ===")
        result = recognize_image(test_image)
        
        if result.get('success'):
            analysis = result['analysis']
            print(f"\nğŸ‰ è¯†åˆ«æˆåŠŸ!")
            print(f"ğŸ“ è¯†åˆ«æ–‡å­—: {result['recognized_text'][:100]}...")
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   - æ±‰å­—æ•°é‡: {analysis['character_count']}")
            print(f"   - å”¯ä¸€å­—ç¬¦: {analysis['unique_characters']}")
            print(f"   - åˆ—æ•°: {analysis['column_count']}")
            print(f"   - å‰20å­—ç¬¦: {analysis['first_20_chars']}")
        else:
            print(f"âŒ è¯†åˆ«å¤±è´¥: {result.get('error')}")
    else:
        print(f"æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨: {test_image}")